# 🧠 Fuzzy Lookup Data Pipeline  

## 📖 Overview  
This project automates the **entire Fuzzy Lookup process** used in operational data matching and cleansing.  
It demonstrates my ability to build **end-to-end ETL pipelines** in **Python** for real-world data engineering workflows.  

The code in this repository is a **sanitized, non-confidential example** adapted from my professional work at *Datavant* for demonstration purposes.  

---

## ⚙️ Project Description  
The **Fuzzy Lookup Data Pipeline** is an automated ETL process written in **Python**, leveraging **pandas** and **RapidFuzz** to extract, clean, and standardize over **100 K rows of operational data** from **Microsoft SQL Server**.  

It replaces a **30-step manual reporting workflow** with a **two-step automated solution**, drastically reducing human effort, error rates, and turnaround time for recurring data reconciliation and reporting tasks.  

---

## 🧩 Key Features  
- 🔄 **Automated ETL Pipeline:** Extracts, transforms, and loads SQL Server data with no manual intervention.  
- 🧹 **Data Standardization:** Cleans and normalizes raw fields using **pandas** string methods and custom logic.  
- 🤝 **Fuzzy Matching with RapidFuzz:** Matches similar records across datasets using configurable similarity thresholds.  
- 📊 **Validation & Reporting:** Generates summary reports highlighting duplicates, mismatches, and confidence scores.  
- 🕒 **Efficiency Gains:** Reduced manual workload from hours to minutes while improving consistency and traceability.  

---

## 🧠 Technical Stack  
| Component | Technology |
|------------|-------------|
| Programming Language | Python 3 |
| Data Libraries | pandas · RapidFuzz · NumPy |
| Database | Microsoft SQL Server |
| Output | Excel / CSV Reports |
| Version Control | Git · GitHub |

---

## 🧾 Example Workflow  
1. **Extract:** Connect to SQL Server and retrieve operational data tables.  
2. **Transform:** Cleanse, reformat, and standardize columns (names, phone numbers, IDs).  
3. **Fuzzy Match:** Apply RapidFuzz ratio scoring to link similar records between tables.  
4. **Export:** Save matched and unmatched datasets into Excel/CSV reports for auditing.  

---

## 📈 Outcomes  
- Decreased reporting cycle from **~2 hours to under 10 minutes**.  
- Reduced error rates and improved data integrity through automated validation.  
- Provided a reusable Python framework adaptable for other matching and ETL use cases.  

---

## 🧠 Learning Takeaways  
Through this project, I strengthened my skills in:
- Building maintainable **ETL pipelines** in Python  
- Implementing **fuzzy matching algorithms** for data reconciliation  
- Using **pandas** for transformation and quality control  
- Writing **clean, documented, and reproducible** data-engineering code  

---

## 📬 Contact  
**Kevin Braman**  
📧 [kevinbraman92@gmail.com](mailto:kevinbraman92@gmail.com)  
💼 [LinkedIn](https://www.linkedin.com/in/kevin-braman-a7974a129/)  
💻 [GitHub](https://github.com/kevinbraman92)  

---

⭐ *If you found this repository useful or inspiring, consider giving it a star!*

